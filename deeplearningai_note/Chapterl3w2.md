## 第二周：机器学习策略（2）(ML Strategy (2))
1. 进行误差分析(手动标记)
   - 例子：
     
     假设你正在调试猫分类器，然后你取得了90%准确率，相当于10%错误，这些错误有不同原因，包括狗识别成猫、其他猫科识别成猫、图片模糊...

     ![](images\ef3a1a483263b2693ecb6c7c1aecc565.png)

     可以用表格来手动记录错误的原因，**进行误差分析**，之后**针对更有改进潜力的问题对算法进行优化**，在下图中，可以分析出应首先优化图片模糊的问题

     ![](images\4502737a321a0f6269ee11cb8f140827.png)
2. 清除标注错误的数据
   
   当发现你的数据有一些标记错误的样本：
   1. 对于training set：深度学习算法对于训练集中的随机错误是相当健壮的（robust），所以如果错误足够随机，那么放着这些错误不管可能也没问题。
   2. 对于dev set：如果这些标记错误严重影响了你在开发集上评估算法的能力，那么就应该去花时间修正错误的标签（下图右）。但是，如果它们没有严重影响到你用开发集评估成本偏差的能力，那么可能就不应该花宝贵的时间去处理（下图左）。
   
      ![](images\fc5d8fbd1124120e01fc4287896faa44.png)
   3. 对应修正开发集数据:
   
      ![](images\9d5b710121594f5a1e1bc5e901be52a8.png)
      1. 确保开发和测试集必须来自相同的分布
      2. 考虑同时检验算法判断正确和判断错误的样本
      3. 你的开发集和测试集来自同一分布非常重要。但如果你的训练集来自稍微不同的分布，通常这是一件很合理的事情
3. 快速搭建你的第一个系统，并进行迭代

   当你想搭建全新的机器学习程序，
   1. 快速设立开发集和测试集还有指标(这样就决定了你的目标所在)
   2. 快速搭好你的第一个系统(一个快速和粗糙的实现)，然后开始迭代，理解算法表现。
   3. 进行偏差方差分析 和 误差分析
4. 使用来自不同分布的数据，进行训练和测试
   - 例：假设你在开发一个手机应用，用户会上传他们用手机拍摄的照片，你想识别用户从应用中上传的图片是不是猫。
     
     数据：
     1. 从互联网上下载的20万张清晰猫图
     2. 1万张来自手机APP的模糊猫图

     ![](images\eb0178687dedc450e1c184b958adeef3.png)

     数据分配方法：
     1. 不推荐方法：将两组数据合并在一起，并把这21万张照片随机分配到训练、开发和测试集中
        - 不推荐原因：记住dev set是你的目标，如果随机分配瞄准的主要目标仍是网络上下载的清晰图片，因此你的大部分精力都用在优化来自网页下载的图片，这其实不是你想要的
     2. 推荐方法：把手机上传的5000张图片分到training set，dev set和testing set分布分配2500张来自手机应用的图片
        - 推荐原因：这么做告诉你的团队，我的开发集包含的数据全部来自手机上传，这是你真正关心的图片分布。
5. 数据分布不匹配时，偏差与方差的分析
   - 做法：随机打散训练集，然后分出一部分训练集作为训练-开发集（training-dev），就像开发集和测试集来自同一分布，训练集、训练-开发集也来自同一分布。

     ![](images\6a3c48f8a71b678c2769165f38523635.png)
   - data mismatch = dev error - train-dev error
     
     ![](images\c5d2293143857294c49859eb875272f5.png)

     图左为反差问题(无法很好地泛化推广到来自同一分布)
     
     图右为数据不匹配问题(算法擅长处理和你关心的数据有不同的分布)
     
6. 处理数据不匹配问题
   1. 做错误分析，尝试了解训练集和开发测试集的具体差异
      - 例：在开发一个语音激活的后视镜应用时候，开发集样本汽车噪音很多，这是开发集和训练集差异之一
   2. **让训练数据与开发集数据更相似**；收集更多和dev/test set来自同一分布的数据进行训练
      - 例：使用人工合成数据，来快速制造更多的训练数据
  
        ![](images\b78b8300183ba2567c53db33d29f99d6.png)
      - 人工合成数据的潜在问题：你只录了一小时车辆背景噪音，那么，你将这1小时汽车噪音回放10,000次，并叠加到在安静的背景下录得的10,000小时数据，这可能导致**你的学习算法对这1小时汽车噪音过拟合**。

7. 迁移学习
   
   - 定义: 把为任务 A 开发的模型作为初始点，重新使用在为任务 B 开发模型的过程中。

   ![](images\965626f5cf666ec7ed093e0f5a0d8b52.png)

   - 例：
     1. 有一个已经训练好的图像识别神经网络(识别猫或狗或鸡...)
     2. 把神经网络最后的输出层拿走
     3. 把数据集换成新的$(x,y)$对，现在这些变成放射科图像，而$y$是你想要预测的诊断，你要做的是初始化最后一层的权重，让我们称之为$w^{[L]}$和$b^{[L]}$随机初始化
     4. 在这个新数据集上重新训练网络，如果你有一个小数据集，就只训练输出层前的最后一层，或者也许是最后一两层。但是如果你有很多数据，那么也许你可以重新训练网络中的所有参数
   - 什么时候迁移学习是有意义的(Task from A to B):
     1. 当任务$A$和任务$B$都有同样的输入$x$时，迁移学习是有意义的
     2. 当任务$A$的数据比任务$B$多得多时，迁移学习意义更大
     3. 如果你觉得任务$A$的低层次特征，可以帮助任务$B$的学习，那迁移学习更有意义一些
8. 多任务学习
   - 定义：训练一个神经网络来执行许多任务，这可以给你更高的性能，比单独完成各个任务更高的性能
   - 例：
     
     在研发无人驾驶车辆，那么你的无人驾驶车可能需要同时检测不同的物体(行人、车辆、停车标志、交通灯...)

     ![](images\91f56940e94af25b0d7a46fa8dde9075.png)

     > 与softmax回归的区别：softmax回归将单个标签分配给单个样本，而多任务学习一张图可以有多个标签
   - 多任务学习什么时候有意义:
     1. 训练的一组任务，可以共用低层次特征
     2. 每个任务的数据量很接近
     3. 可以训练一个足够大的神经网络能同时做好所有的工作
   > 实际上迁移学习比多任务学习使用频率更高
9. 什么是端到端的深度学习？
   - 定义：整个学习的流程并不进行人为的子问题划分，而是完全交给深度学习模型直接学习从原始数据到期望输出的映射。
     
     ![](images\c31b0402d98fb34aecf167e65f83cb37.png)
     
10. 是否要使用端到端的深度学习？
    - 优点：
      1. 端到端学习真的只是让数据说话。这样做可能更能够捕获数据中的任何统计信息，而不是被迫引入人类的成见。
      2. 所需手工设计的组件更少，所以这也许能够简化你的设计工作流程。
    - 缺点：
      1. 可能需要大量的数据。
      2. 排除了可能有用的手工设计组件。